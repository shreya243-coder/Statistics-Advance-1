{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics Advance part 1"
      ],
      "metadata": {
        "id": "uG08nJSnkFnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Random Variable\n",
        "A **random variable** is a numerical outcome of a random phenomenon. It can take on different values based on the outcome of a random event.\n",
        "\n",
        "2. Types of Random Variables\n",
        "\n",
        "i. **Discrete Random Variables**: These take on a countable number of distinct values (e.g., the number of heads in a series of coin flips).\n",
        "\n",
        "ii. **Continuous Random Variables**: These can take on any value within a given range (e.g., the height of individuals).\n",
        "\n",
        "3. Discrete vs. Continuous Distributions\n",
        "- **Discrete Distributions** describe random variables that can take on distinct, separate values (e.g., binomial distribution).\n",
        "- **Continuous Distributions** describe random variables that can take on any value within a continuous range (e.g., normal distribution).\n",
        "\n",
        "4. Probability Distribution Functions (PDF)\n",
        "A **probability distribution function** (PDF) describes the likelihood of different outcomes for a random variable. For discrete variables, it's represented as a probability mass function (PMF); for continuous variables, it's a function that describes the density of probabilities.\n",
        "\n",
        "5. Cumulative Distribution Functions (CDF)\n",
        "The **cumulative distribution function** (CDF) gives the probability that a random variable is less than or equal to a certain value. It differs from the PDF in that the PDF provides probabilities for individual outcomes, while the CDF accumulates these probabilities.\n",
        "\n",
        "6. Discrete Uniform Distribution\n",
        "A **discrete uniform distribution** is a type of distribution where each outcome has an equal probability of occurring (e.g., rolling a fair die).\n",
        "\n",
        "7. Key Properties of a Bernoulli Distribution\n",
        "- It has two possible outcomes: success (1) and failure (0).\n",
        "- The probability of success is denoted as \\( p \\), and the probability of failure is \\( 1 - p \\).\n",
        "- The mean is \\( p \\) and the variance is \\( p(1 - p) \\).\n",
        "\n",
        "8. Binomial Distribution\n",
        "The **binomial distribution** models the number of successes in a fixed number of independent Bernoulli trials. It's used in scenarios like flipping a coin multiple times.\n",
        "\n",
        "9. Poisson Distribution\n",
        "The **Poisson distribution** models the number of events occurring in a fixed interval of time or space, with events happening independently (e.g., the number of phone calls received in an hour).\n",
        "\n",
        "10. Continuous Uniform Distribution\n",
        "A **continuous uniform distribution** describes a situation where all outcomes in a given interval are equally likely (e.g., choosing a random number between 0 and 1).\n",
        "\n",
        "11. Characteristics of a Normal Distribution\n",
        "- It is symmetric and bell-shaped.\n",
        "- The mean, median, and mode are all equal.\n",
        "- The spread is determined by the standard deviation.\n",
        "\n",
        "12. Standard Normal Distribution\n",
        "The **standard normal distribution** is a normal distribution with a mean of 0 and a standard deviation of 1. It is important because it allows for the use of Z-scores to standardize different normal distributions for comparison.\n",
        "\n",
        "13. Central Limit Theorem (CLT)\n",
        "The **Central Limit Theorem** states that, given a sufficiently large sample size, the sampling distribution of the sample mean will be approximately normally distributed, regardless of the original distribution's shape. This is critical because it justifies the use of normal distribution approximations in many statistical methods.\n",
        "\n",
        "14. Relationship Between CLT and Normal Distribution\n",
        "The CLT establishes that the distribution of sample means will tend to be normal, enabling the application of normal probability methods to infer properties about population means.\n",
        "\n",
        "15. Application of Z Statistics in Hypothesis Testing\n",
        "**Z statistics** are used to determine how many standard deviations an observation is from the mean. They help in hypothesis testing by comparing the Z-score to critical values.\n",
        "\n",
        "16. Calculating a Z-score\n",
        "The **Z-score** is calculated as:\n",
        "\\[\n",
        "Z = \\frac{(X - \\mu)}{\\sigma}\n",
        "\\]\n",
        "where \\( X \\) is the value, \\( \\mu \\) is the mean, and \\( \\sigma \\) is the standard deviation. It represents the number of standard deviations a data point is from the mean.\n",
        "\n",
        "17. Point Estimates and Interval Estimates\n",
        "- **Point estimates** provide a single value as an estimate of a population parameter (e.g., sample mean).\n",
        "- **Interval estimates** provide a range of values (e.g., confidence intervals) within which the parameter is expected to lie.\n",
        "\n",
        "18. Significance of Confidence Intervals\n",
        "**Confidence intervals** indicate the range within which we expect the true population parameter to fall, providing a measure of uncertainty.\n",
        "\n",
        "19. Relationship Between Z-score and Confidence Interval\n",
        "The Z-score is used to determine the margin of error for confidence intervals. A higher Z-score corresponds to a wider confidence interval, indicating greater uncertainty.\n",
        "\n",
        "20. Z-scores in Comparing Distributions\n",
        "Z-scores standardize different distributions, allowing for comparison of values from different datasets on a common scale.\n",
        "\n",
        "21. Assumptions for Applying the Central Limit Theorem\n",
        "i. The samples should be independent.\n",
        "ii. The sample size should be sufficiently large (typically \\( n \\geq 30 \\)).\n",
        "iii. The population should have a finite mean and variance.\n",
        "\n",
        "22. Expected Value in a Probability Distribution\n",
        "The **expected value** is a measure of the center of a probability distribution, representing the long-term average outcome of a random variable.\n",
        "\n",
        "23. Probability Distribution and Expected Outcome\n",
        "A probability distribution defines how probabilities are assigned to different outcomes, and the expected outcome is calculated as the weighted average of all possible outcomes, using their probabilities.\n"
      ],
      "metadata": {
        "id": "sVyMXuolkYYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V6C51Nz5oW3t"
      }
    }
  ]
}